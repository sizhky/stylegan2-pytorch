{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "stylegan-2-style-transfer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNqp9T1ITbo1iTnUV2psnk8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sizhky/stylegan2-pytorch/blob/master/stylegan_2_style_transfer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXaRArz5R_Zh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "9cfa909c-3b39-4f10-cf48-3e6a25830989"
      },
      "source": [
        "%%time\n",
        "import os\n",
        "\n",
        "if not os.path.exists('stylegan2-pytorch'):\n",
        "    !git clone https://github.com/sizhky/stylegan2-pytorch\n",
        "    !wget --quiet https://github.com/ninja-build/ninja/releases/download/v1.8.2/ninja-linux.zip\n",
        "    !sudo unzip -q ninja-linux.zip -d /usr/local/bin/\n",
        "    !sudo update-alternatives --install /usr/bin/ninja ninja /usr/local/bin/ninja 1 --force\n",
        "    !rm ninja-linux.zip\n",
        "    !pip install -U -q PyDrive torch_snippets\n",
        "    from pydrive.auth import GoogleAuth\n",
        "    from pydrive.drive import GoogleDrive\n",
        "    from google.colab import auth\n",
        "    from oauth2client.client import GoogleCredentials\n",
        "    auth.authenticate_user()\n",
        "    gauth = GoogleAuth()\n",
        "    gauth.credentials = GoogleCredentials.get_application_default()\n",
        "    drive = GoogleDrive(gauth) \n",
        "    downloaded = drive.CreateFile({'id':\"1PQutd-JboOCOZqmd95XWxWrO8gGEvRcO\"})   # replace the id with id of file you want to access\n",
        "    downloaded.GetContentFile('5500000.pth')        # replace the file name with your file\n",
        "%cd stylegan2-pytorch"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/stylegan2-pytorch\n",
            "CPU times: user 852 µs, sys: 0 ns, total: 852 µs\n",
            "Wall time: 859 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1koJbacORiV",
        "colab_type": "text"
      },
      "source": [
        "### Playing with Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GY_jrNqLAU53",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "48abbdd6-c6e9-48c1-ea61-d061891e98b2"
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "from torch_snippets import *\n",
        "from generate import Generator\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "device = 'cuda'\n",
        "generator = Generator(size=256, style_dim=512, \n",
        "                      n_mlp=8, channel_multiplier=2)\n",
        "generator.load_state_dict(torch.load('../5500000.pth')['g_ema'], strict=False)\n",
        "generator.eval().to(device);"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/setuptools/distutils_patch.py:26: UserWarning: Distutils was imported before Setuptools. This usage is discouraged and may exhibit undesirable behaviors or errors. Please use Setuptools' objects directly or at least import Setuptools first.\n",
            "  \"Distutils was imported before Setuptools. This usage is discouraged \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2gc2gelu4Hc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def interpolate_two_points(p1, p2, n_steps=8):\n",
        "    ratios = torch.linspace(0, 1, steps=n_steps)\n",
        "    vectors = []\n",
        "    for ratio in ratios:\n",
        "        v = (1.0 - ratio) * p1 + ratio * p2\n",
        "        vectors.append(v)\n",
        "    return torch.stack(vectors)\n",
        "def interpolate_four_points(p1,p2,p3,p4,n_steps=8):\n",
        "    z1 = interpolate_two_points(p1, p2, n_steps)\n",
        "    z2 = interpolate_two_points(p3, p4, n_steps)\n",
        "    zs = []\n",
        "    for _z1,_z2 in zip(z1, z2):\n",
        "        zs.append(interpolate_two_points(_z1,_z2, n_steps))\n",
        "    zs = torch.cat(zs)\n",
        "    return zs\n",
        "device = 'cuda'\n",
        "with torch.no_grad():\n",
        "    steps = 8\n",
        "    # corner_zs = torch.randn(4, 14, 512, device=device)\n",
        "    # zs = interpolate_four_points(*corner_zs, steps)\n",
        "    # dumpdill(zs, 'noise.vectors')\n",
        "\n",
        "    zs = loaddill('noise.vectors')\n",
        "    zs = generator.get_latent(zs)\n",
        "    sample, _ = generator([zs])\n",
        "    save_image(sample, 'sample/interpolations.png', nrow=steps, normalize=True, range=(-1,1)) "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYqBg14QeOmQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "styles = {\n",
        "    'frontal-black-hair-female': zs[56],\n",
        "    'kid-worried': zs[39],\n",
        "    'bearded-man': zs[63]\n",
        "}\n",
        "\n",
        "# with torch.no_grad():\n",
        "#     latents = [style_vec[None] for style,style_vec in styles.items()]\n",
        "#     latents = torch.cat(latents)\n",
        "\n",
        "##############################  WORKED  ##############################\n",
        "def transfer_coarse_latent(source_styles, target_style):\n",
        "    originals, _ = generator(source_styles)\n",
        "    style_transferred, _ = generator(source_styles, \n",
        "                                  coarse_latents=target_style[:,:4].repeat(len(source_styles),1,1))\n",
        "    samples = torch.cat([originals, style_transferred], 0)\n",
        "    save_image(samples, f'sample/coarse_transfer_{name}.png', nrow=len(samples)//2, normalize=True, range=(-1,1))\n",
        "\n",
        "def transfer_middle_latent(source_styles, target_style):\n",
        "    originals, _ = generator(source_styles)\n",
        "    style_transferred, _ = generator(source_styles, \n",
        "                                  middle_latents=target_style[:,4:10].repeat(len(source_styles),1,1))\n",
        "    samples = torch.cat([originals, style_transferred], 0)\n",
        "    save_image(samples, f'sample/middle_transfer_{name}.png', nrow=len(samples)//2, normalize=True, range=(-1,1))\n",
        "\n",
        "\n",
        "def transfer_fine_latent(source_styles, target_style):\n",
        "    originals, _ = generator(source_styles)\n",
        "    style_transferred, _ = generator(source_styles, \n",
        "                                  fine_latents=target_style[:,10:].repeat(len(source_styles),1,1))\n",
        "    samples = torch.cat([originals, style_transferred], 0)\n",
        "    save_image(samples, f'sample/fine_transfer_{name}.png', nrow=len(samples)//2, normalize=True, range=(-1,1))\n",
        "\n",
        "for name, latent in styles.items():\n",
        "    z = torch.randn(5, 14, 512, device=device)\n",
        "    z = generator.get_latent(z)\n",
        "    z = torch.cat([latent[None], z])\n",
        "\n",
        "    transfer_coarse_latent([z.clone()], latent[None].clone())\n",
        "    transfer_middle_latent([z.clone()], latent[None].clone())\n",
        "    transfer_fine_latent([z.clone()], latent[None].clone())\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHRJb93vWbju",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "92ebae88-5ccb-4eda-82fd-957abd13cc9d"
      },
      "source": [
        "import zipfile\n",
        "lista_files = Glob('sample')\n",
        "with zipfile.ZipFile('samples.zip', 'w') as zipMe:\n",
        "    for file in lista_files:\n",
        "        zipMe.write(file, compress_type=zipfile.ZIP_DEFLATED)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-08-01 20:42:31.888 | INFO     | torch_snippets.loader:Glob:150 - 15 files found at sample\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DcgUIkuPwwek",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}